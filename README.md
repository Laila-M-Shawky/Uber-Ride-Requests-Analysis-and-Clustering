# ğŸš• Uber Ride Requests Analysis and Clustering

![Demo](Uber%20GIF%20by%20Mashable.gif)

- This project analyzes Uber ride request data to uncover demand patterns and driver behavior using Python.
- It includes cleaning, feature engineering, visualizations, and clustering of pickup locations with K-Means.

---

## ğŸ“Œ Description

A comprehensive end-to-end data science project analyzing real-world Uber ride request data using Python.

---

### ğŸ”„ Project Workflow:

- **Data Cleaning:**
  - Parsed and standardized datetime columns (`Request timestamp`, `Drop timestamp`).
  - Handled missing values in `Driver id` and `Drop timestamp` without dropping large portions of data.
  - Cleaned categorical fields like `Status` and `Pickup point` (e.g., stripping whitespace, title casing).

- **Feature Engineering:**
  - Extracted informative time-based features:
    - `Request hour`, `Request day`, and `Request Date`
    - `Trip duration` (as timedelta and in minutes)
    - `Time slot` classification (Morning, Afternoon, Evening, Night)
    - Boolean flags like `Driver Available` and `Is Completed`

- **Data Visualization:**
  - Identified:
    - Demand peaks (morning and evening)
    - Driver inactivity periods
    - Request trends by hour, day, and location
    - Cancellation patterns and completion rates

- **Clustering with K-Means (k=5):**
  - Simulated pickup coordinates and applied clustering to segment NYC into 5 operational zones.
  - Visualized high-density clusters vs. low-demand zones.

---

### ğŸ’¡ Key Insights:

-  **Peak Demand:** Evening hours (5â€“9 PM) have highest request volume but lowest driver availability.
-  **Driver Inactivity:** Fridays show high inactivity despite high demand.
-  **Trip Duration:** Early morning trips (12â€“4 AM) are slightly longer.
-  **Top Drivers:** Most top-10 drivers completed between 20â€“22 trips â€” tight distribution.
-  **Pickup Patterns:** Majority of requests originate from the **City**; **Airport** has high rate of "No Cars Available".

---

### ğŸ› ï¸ Recommendations:

-  Incentivize drivers during evening peaks and on inactive days (e.g., Friday).
-  Promote early morning hours (12â€“3 AM) with offers and safety campaigns.
-  Use K-Means zones to operationally split NYC for optimized driver distribution.
-  Coordinate with airports for better pickup logistics & reduce city cancellations.

---

## ğŸ—‚ï¸ Dataset

- **File Name**: `Uber Request Data.csv`
- **Source**: Provided by course instructors
- **Format**: Tab-separated values (`.tsv`)
- **Rows**: 6,745 Uber ride requests
- **Description**: Raw log of Uber rides captured over a period of several days. Used for analyzing ride demand, driver activity, cancellations, and trip patterns.

### ğŸ”‘ Key Columns:

- `Request id`: Unique numeric ID for each ride request  
- `Pickup point`: Location where the ride was requested from (`City` or `Airport`)  
- `Driver id`: ID of the driver assigned (may be missing if unassigned)  
- `Status`: Trip outcome - `Trip Completed`, `Cancelled`, or `No Cars Available`  
- `Request timestamp`: Timestamp when the user requested the ride  
- `Drop timestamp`: Timestamp when the trip was completed (may be null)

---

## âš™ï¸ Installation

### Requirements

To get started, make sure you have **Python 3.10+** installed on your system.  
Then install all required libraries by running:

```bash
pip install -r requirements.txt
```
---

### ğŸ“¦ Core Libraries Used

- `pandas` â†’ data manipulation  
- `numpy` â†’ numerical operations  
- `matplotlib`, `seaborn` â†’ visualizations  
- `scikit-learn` â†’ KMeans clustering  
- `python-dateutil` â†’ parsing flexible timestamps  

---

### âœ… Setup Checklist

Ensure the following are in place before running the project:

-  `data/Uber Request Data.csv` is inside the `data/` folder  
-  `src/` contains all modular code files  
-  `output/` folder exists for saving processed results  
-  `main.py` exists in the project root  

---

### ğŸš€ Run the Full Pipeline

Run the entire analysis and visualization pipeline with:

```bash
python main.py
```
---

## ğŸ“½ï¸ Inference Demo

Once the project is launched via `main.py`, the following steps are performed:

-  Loads and parses the raw Uber request dataset  
-  Cleans and preprocesses timestamps, missing values, and categories  
-  Extracts useful features like time slot, duration, and weekday  
-  Adds simulated geo-coordinates and clusters pickup points using **K-Means**  
-  Displays visual insights (trip patterns, demand peaks, hotspot regions)  
-  Saves enriched dataset to `output/Uber with features.csv`  

 Visualizations appear live using **matplotlib** and **seaborn**  
 Final processed dataset is reusable for further analysis  

---

## ğŸ“ Project Structure

The project is organized in a modular, production-ready structure:

```
Uber-Trip-Analysis/
â”‚
â”œâ”€â”€ data/                         # Raw input data (Uber Request Data.csv)
â”‚   â””â”€â”€ Uber Request Data.csv
â”‚
â”œâ”€â”€ output/                       # Final enriched data & visual assets
â”‚   â””â”€â”€ Uber with features.csv
â”‚
â”œâ”€â”€ src/                          # All modular processing code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loading_and_exploration.py
â”‚   â”œâ”€â”€ data_cleaning_and_preprocessing.py
â”‚   â”œâ”€â”€ data_feature_engineering.py
â”‚   â”œâ”€â”€ data_visualization.py
â”‚   â”œâ”€â”€ location_clustering.py
â”‚   â””â”€â”€ save_transformed_data.py
â”‚
â”œâ”€â”€ main.py                       # Master pipeline to run the entire workflow
â”œâ”€â”€ requirements.txt              # Python dependencies
â””â”€â”€ README.md                     # Project documentation
```

---

## ğŸ‘¥ Contributors

-   **Malak Salem**: Data loading, exploration, and reporting key patterns.
-  **Laila Shawky**: Cleaning and feature engineering (timestamps, nulls, derived fields).
-  **Jumanah Rushdi**: Visualizations and spatial clustering (K-Means on pickup points).

---

## ğŸ“ License

- Open source under the **MIT License**.  
- Free to use, modify, and distribute with attribution.
